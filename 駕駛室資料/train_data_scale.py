# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from pathlib import Path

# === 1. è®€å®Œæ•´è³‡æ–™ =========================================================
df_all = pd.read_csv("train_data.csv")
df_all['datetime'] = pd.to_datetime(df_all['datetime'])

# === 2. ä¾†æºæ™‚é–“åƒæ•¸è¨­å®š (è¦è¤‡è£½å“ªä¸€æ®µåŸå§‹è³‡æ–™) ================================
# start_time = pd.Timestamp("2024-06-17 14:20:00")
# end_time   = pd.Timestamp("2024-06-17 16:20:00")

start_time = pd.Timestamp("2025-02-07 11:28:00")
end_time   = pd.Timestamp("2025-02-07 13:03:00")
duration   = end_time - start_time  # è¨ˆç®—å€æ®µé•·åº¦

# === 3. å¤šæ¬„ä½æ•…éšœè¨­å®š ======================================================
# æ³¨æ„ï¼šåˆ—è¡¨å…§çš„æ•¸å€¼æ•¸é‡æ±ºå®šäº†æœƒç”¢ç”Ÿå¹¾æ®µè³‡æ–™
# ä¾‹å¦‚ï¼š[0.9, 0.8, 0.7] æœƒç”¢ç”Ÿ 3 æ®µé€£çºŒçš„æ™‚é–“è³‡æ–™
fault_specs = {
    # å£“ç¸®æ©Ÿ2025-03-01 00:00:14   2025-03-01 05:58:09
    # 'comp_current_1':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'comp_current_2':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'hp_comp_1':  ("scale_step", [1.02, 1.04, 1.06]),
    # 'hp_comp_2':  ("scale_step", [1.02, 1.04, 1.06]),
    # 'lp_comp_1':  ("scale_step", [1.01, 1.02, 1.03]),
    # 'lp_comp_2':  ("scale_step", [1.01, 1.02, 1.03]),

    # # å†·å‡é¢¨æ‰‡2025-03-01 06:00:14   2025-03-01 11:58:09
    # 'cond_current_1':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'cond_current_2':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'hp_comp_1':  ("scale_step", [1.08, 1.15, 1.23]),
    # 'hp_comp_2':  ("scale_step", [1.08, 1.15, 1.23]),
    # 'comp_current_1':  ("scale_step", [1.05, 1.1, 1.15]),
    # 'comp_current_2':  ("scale_step", [1.05, 1.1, 1.15]),
    # 'lp_comp_1':  ("scale_step", [1.02, 1.04, 1.06]),
    # 'lp_comp_2':  ("scale_step", [1.02, 1.04, 1.06]),

    # # è’¸ç™¼é¢¨æ‰‡2025-03-01 12:00:14   2025-03-01 17:58:09
    # 'fan_current_1':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'fan_current_2':  ("scale_step", [1.1, 1.2, 1.3]),
    # 'lp_comp_1':  ("shift_step", [0.98, 0.96, 0.94]),
    # 'lp_comp_2':  ("shift_step", [0.98, 0.96, 0.94]),
    # 'comp_current_1':  ("shift_step", [0.99, 0.98, 0.97]),
    # 'comp_current_2':  ("shift_step", [0.99, 0.98, 0.97]),
    # 'hp_comp_1':  ("shift_step", [0.99, 0.98, 0.97]),
    # 'hp_comp_2':  ("shift_step", [0.99, 0.98, 0.97]),
    
    # # åŠ ç†±å™¨2025-03-01 18:00:53   2025-03-01 22:44:59
    'heater_temp':  ("scale_step", [0.9, 0.8, 0.7]),
    'return_air_temp':  ("scale_step", [0.98, 0.96, 0.94]),
}

# å–å¾—è¦ç”¢ç”Ÿçš„æ®µæ•¸ (ä»¥ç¬¬ä¸€å€‹æ¬„ä½çš„è¨­å®šé•·åº¦ç‚ºæº–)
num_scenarios = len(next(iter(fault_specs.values()))[1])
print(f"é è¨ˆç”¢ç”Ÿ {num_scenarios} å€‹é€£çºŒå€æ®µ...")

# === 4. æŠ½å‡ºåŸºç¤å€æ®µ ========================================================
base_segment = df_all[df_all['datetime'].between(start_time, end_time)].copy()
base_segment = base_segment.drop_duplicates('datetime').sort_values('datetime')

# è¨­å®šæ¨¡æ“¬èµ·å§‹æ™‚é–“é»
sim_start_base = pd.Timestamp("2025-03-01 18:00:00")

# === 5. è¿´åœˆç”Ÿæˆå¤šæ®µè³‡æ–™ (å–ä»£åŸæœ¬çš„åˆ†æ®µé‚è¼¯) =================================
generated_segments = []

for i in range(num_scenarios):
    # è¤‡è£½ä¸€ä»½åŸºç¤è³‡æ–™
    current_segment = base_segment.copy()
    
    # é‡å°æ¯å€‹è¨­å®šæ¬„ä½é€²è¡Œæ•´æ®µèª¿æ•´
    for col, (mode, step_values) in fault_specs.items():
        if col not in current_segment.columns:
            continue
            
        # å–å¾—ç•¶å‰æ®µæ•¸å°æ‡‰çš„æ•¸å€¼ (ä¾‹å¦‚ç¬¬ i å€‹å€¼)
        # å¦‚æœè¨­å®šå€¼ä¸å¤ é•·ï¼Œå°±å–æœ€å¾Œä¸€å€‹
        val = step_values[i] if i < len(step_values) else step_values[-1]
        
        if mode == "scale_step":
            current_segment[col] *= val
        elif mode == "shift_step":
            current_segment[col] += val
            
    # === 6. æ™‚é–“å¹³ç§»è¨ˆç®— ===
    # æ¯ä¸€æ®µçš„æ™‚é–“èµ·é» = åŸºç¤èµ·é» + (ç¬¬ i æ®µ * å–®æ®µé•·åº¦)
    # é€™æ¨£æœƒæŠŠè³‡æ–™è®Šæˆï¼š[ç¬¬1æ®µ][ç¬¬2æ®µ][ç¬¬3æ®µ] é€£çºŒæ¥åœ¨ä¸€èµ·
    current_target_start = sim_start_base + (i * duration)
    
    # è¨ˆç®—è©²æ®µçš„æ™‚é–“ä½ç§»é‡
    time_shift = current_target_start - start_time
    current_segment['datetime'] += time_shift
    
    generated_segments.append(current_segment)

# åˆä½µæ‰€æœ‰ç”Ÿæˆçš„ç‰‡æ®µ
sim_df = pd.concat(generated_segments)

# === 7. æª¢æŸ¥ä¸¦åˆªé™¤ç›®æ¨™å€é–“çš„èˆŠè³‡æ–™ ==========================================
# å–å¾—æ–°è³‡æ–™çš„æ™‚é–“ç¯„åœ
sim_start = sim_df['datetime'].min()
sim_end = sim_df['datetime'].max()

print(f"-> æº–å‚™æ’å…¥è³‡æ–™ç¯„åœ: {sim_start} è‡³ {sim_end}")

# å»ºç«‹é®ç½©ï¼šæ‰¾å‡ºåŸå§‹è³‡æ–™ä¸­ï¼Œè½åœ¨é€™å€‹æ™‚é–“ç¯„åœå…§çš„è³‡æ–™
mask_exist = (df_all['datetime'] >= sim_start) & (df_all['datetime'] <= sim_end)
cnt_exist = mask_exist.sum()

if cnt_exist > 0:
    print(f"âš ï¸ è­¦å‘Šï¼šç›®æ¨™æ™‚é–“æ®µå…§å·²æœ‰ {cnt_exist} ç­†è³‡æ–™ï¼Œæ­£åœ¨åˆªé™¤èˆŠè³‡æ–™ä»¥é¿å…é‡è¤‡...")
    df_all = df_all[~mask_exist].copy()
else:
    print("âœ… ç›®æ¨™æ™‚é–“æ®µå…§ç„¡è³‡æ–™ï¼Œç›´æ¥æ‹¼æ¥ã€‚")

# === 8. åˆä½µä¸¦è¼¸å‡º CSV =====================================================
final_df = pd.concat([df_all, sim_df]).sort_values('datetime').reset_index(drop=True)
final_df = final_df[df_all.columns]  # ä¿æŒæ¬„ä½é †åº

out_dir = Path("dataset"); out_dir.mkdir(exist_ok=True)
out_path = out_dir/"train_data.csv"

# ä¿æŒå…©ä½å°æ•¸æ ¼å¼
final_df.to_csv(out_path, index=False, encoding='utf-8', float_format='%.2f')

print("âœ… å·²ç”¢ç”Ÿï¼š", out_path.resolve())
print(f"ğŸ“Š ç¸½å…±æ–°å¢è³‡æ–™ç­†æ•¸: {len(sim_df)}")
print("ğŸ” é‡è¤‡æ™‚é–“æˆ³ = ", final_df['datetime'].duplicated().sum())